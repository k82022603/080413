{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4de37a36-06cd-4d22-b29b-b0e8ed0898ae",
   "metadata": {},
   "source": [
    "# 모델 I/O\n",
    "## 1. 라이브러리 설치\n",
    "- 아나콘다에서 다음 라이브러리를 설치합니다. 다음 코드는 한줄씩 실행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab52b8bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (0.2.12)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (from langchain) (2.0.31)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (from langchain) (3.10.0)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.27 in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (from langchain) (0.2.28)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (from langchain) (0.2.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (from langchain) (0.1.96)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (from langchain) (1.24.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (from langchain) (2.8.2)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (from langchain) (8.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.3.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.27->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.27->langchain) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.27->langchain) (4.11.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.6)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (from requests<3,>=2->langchain) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (from requests<3,>=2->langchain) (2024.7.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.27->langchain) (3.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd337020",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28b9d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install huggingface-hub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987a2215-65c3-4e43-959a-2f118c8bbee3",
   "metadata": {},
   "source": [
    "## 2. 프롬프트 생성 \n",
    "- 실행해볼 코드는 프롬프트와 관련된 것입니다. 프롬프트 생성을 위해 PromptTemplate를 사용합니다. \n",
    "- PromptTemplate은 LLM에 문장을 전달하기 전에 문장 구성을 편리하게 해주는 역할을 합니다. \n",
    "- 즉 말 그대로 LLM이 어떤 문장을 만들어야 하는지를 알려주는 역할을 하죠. \n",
    "- 다음은 제품(Product)만 바뀌고 나머지 문구는 고정해서 출력하는 PromptTemplate에 대한 사용 예시 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52652a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "template = \"{product}를 홍보하기 위한 좋은 문구를 추천해줘?\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"product\"],\n",
    "    template=template,\n",
    ")\n",
    "\n",
    "prompt.format(product=\"카메라\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0959238-945c-4714-98e0-a697bb8984f9",
   "metadata": {},
   "source": [
    "## 3. LLM 호출\n",
    "- LLM은 오픈AI와 구글에서 제공하는 모델을 사용합니다. 프롬프트는 \"진희는 강아지를 키우고 있습니다. 진희가 키우고 있는 동물은?\"이며, \n",
    "- 이에 따라 모델을 거쳐 나오는 겨로가인 컬플리션은 \"강아지\"가 되어야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244ed60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-\" #openai 키 입력\n",
    "\n",
    "#from langchain.chat_models import ChatOpenAI #The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. \n",
    "from langchain_openai import ChatOpenAI\n",
    "llm1 = ChatOpenAI(temperature=0.1,  # 창의성 0.1으로 설정 \n",
    "                 model_name='gpt-4o-mini',  # 모델명 #gpt-4o-mini #gpt-3.5-turbo-16k \n",
    "                 )\n",
    "\n",
    "question = \"진희는 강아지를 키우고 있습니다. 진희가 키우고 있는 동물은?\"\n",
    "#print(llm1.predict(question)) # The method `BaseChatModel.predict` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
    "print(llm1.invoke(question))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f6c4af-29a9-4525-b911-16abab41400a",
   "metadata": {},
   "source": [
    "- 메타에서 제공하는 모델을 사용해 실행해봅니다.\n",
    "  [meta-llama/Meta-Llama-3-8B-Instruct](https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct)\n",
    "- Meta-Llama-3-8B-Instruct 모델은 80억 개의 파라미터를 가진 중간 크기의 언어 모델로, 명령 기반 응답 생성에 최적화되어 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3335bb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\"  #허깅페이스 키 입력\n",
    "\n",
    "#from langchain import HuggingFaceHub #The class `HuggingFaceHub` was deprecated in LangChain 0.0.21 and will be removed in 0.3.0\n",
    "#llm2 = HuggingFaceHub(repo_id = \"google/flan-t5-xxl\", model_kwargs={\"temperature\":0.8, \"max_length\":512})\n",
    "\n",
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "llm2 = HuggingFaceEndpoint(\n",
    "    repo_id=\"meta-llama/Meta-Llama-3-8B-Instruct\", \n",
    "    task=\"text-generation\",\n",
    "    max_new_tokens=100,\n",
    "    temperature=0.1,\n",
    "    do_sample=False,\n",
    ")\n",
    "\n",
    "question = \"진희는 강아지를 키우고 있습니다. 진희가 키우고 있는 동물은?\"\n",
    "completion = llm2.invoke(question)\n",
    "print(completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f79f5e-f87d-4af3-bd98-88381e300cf1",
   "metadata": {},
   "source": [
    "## 4. 모델 성능 비교\n",
    "- 랭체인에서 제공하는 ModelLaboratory을 이용하면 모델의 성능을 비교해볼 수 있습니다. \n",
    "- lim1은 오픈AI, lim2는 메타에서 제공하는 모델입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ef58ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.model_laboratory import ModelLaboratory\n",
    "model_lab = ModelLaboratory.from_llms([llm1, llm2])\n",
    "model_lab.compare(\"대한민국의 가을은 몇 월부터 몇 월까지야?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833b0468-a2ec-4816-b204-43a3c4e225ef",
   "metadata": {},
   "source": [
    "## 5. 출력 파서 (Output Parser)\n",
    "- 파서를 CommaSeparatedListOutputParser로 초기화한 후 출력 형식을 지정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28347b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "#from langchain.chat_models import ChatOpenAI #The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. \n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0,  # 창의성 0으로 설정 \n",
    "                 max_tokens=2048,  # 최대 토큰수\n",
    "                 model_name='gpt-4o-mini',  # 모델명 #gpt-4o-mini #gpt-3.5-turbo-16k\n",
    "                )\n",
    "\n",
    "output_parser = CommaSeparatedListOutputParser() #파서 초기화\n",
    "format_instructions = output_parser.get_format_instructions() #출력 형식 지정\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"7개의 팀을 이름순서대로 보여줘 {subject}.\\n{format_instructions}\",\n",
    "    input_variables=[\"subject\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions}\n",
    ")\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b9d08f-5977-40db-aa92-c75276df6bbc",
   "metadata": {},
   "source": [
    "- 지정된 CommaSeparatedListOutputParser 출력을 확인해보기 위해 \"한국의 야구팀은?\"이라고 질의를 해봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68f3985",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"한국의 야구팀은?\"\n",
    "\n",
    "# 출력 결과 생성\n",
    "#output = llm.predict(text=prompt.format(subject=query)) #The method `BaseChatModel.predict` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead \n",
    "\n",
    "# 출력 결과 생성\n",
    "response = llm.invoke(prompt.format(subject=query))\n",
    "\n",
    "# 실제 텍스트 추출\n",
    "# llm.invoke 메서드가 AIMessage 객체를 반환하기 때문에, AIMessage 객체에서 실제 텍스트를 추출하려면 content 속성을 사용해야 합니다.\n",
    "output = response.content\n",
    "\n",
    "# 출력에 대한 포맷 변경\n",
    "parsed_result = output_parser.parse(output)\n",
    "print(parsed_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982a0bab-f9d0-4b8f-8673-a49d7433b6ce",
   "metadata": {},
   "source": [
    "## 6. langchain_openai.chat_models.base.ChatOpenAI\n",
    "- https://api.python.langchain.com/en/latest/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15aa9c79-e6c8-4438-85e6-fedced237c12",
   "metadata": {},
   "source": [
    "### 6.1 Invoke:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7fa8f8-2af2-4b2a-939d-3592c1a12589",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"20개의 팀을 이름순서대로 보여줘\",\n",
    "    ),\n",
    "    (\"human\", \"한국의 야구팀은?\"),\n",
    "]\n",
    "llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030d48f8-d928-4fd0-a0f1-ff29219959d1",
   "metadata": {},
   "source": [
    "### 6.2 Stream:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb52d26c-0294-4067-831f-0ae0af8ed284",
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk in llm.stream(messages):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285b5cea-6195-48e9-af1f-853398169e95",
   "metadata": {},
   "source": [
    "### 6.3 Async:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45022ca1-308a-4d93-afb7-d64600233413",
   "metadata": {},
   "outputs": [],
   "source": [
    "await llm.ainvoke(messages)\n",
    "\n",
    "# stream:\n",
    "# async for chunk in (await llm.astream(messages))\n",
    "\n",
    "# batch:\n",
    "#await llm.abatch([messages])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7cd493-ac1e-477d-8a30-e3c031c14193",
   "metadata": {},
   "source": [
    "## 7. Output Parsers Types\n",
    "### https://python.langchain.com/v0.1/docs/modules/model_io/output_parsers/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca62b5c7-81e1-4bee-be44-a4cd65824515",
   "metadata": {},
   "source": [
    "### 7.1 CSV parser (CommaSeparatedListOutputParser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fa92d8-4566-4c72-b5b0-818823dca9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "prompt = PromptTemplate(\n",
    "    template=\"List five {subject}.\\n{format_instructions} in Korean\",\n",
    "    input_variables=[\"subject\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions},\n",
    ")\n",
    "\n",
    "model = ChatOpenAI(temperature=0)\n",
    "\n",
    "chain = prompt | model | output_parser\n",
    "\n",
    "chain.invoke({\"subject\": \"ice cream flavors\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c7c663-c080-4124-a094-625dbe1971cb",
   "metadata": {},
   "source": [
    "### 7.2 Datetime parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424b1aff-ffac-4cab-b1c3-39fafab44884",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import DatetimeOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "output_parser = DatetimeOutputParser()\n",
    "template = \"\"\"Answer the users question:\n",
    "\n",
    "{question}\n",
    "\n",
    "{format_instructions}\"\"\"\n",
    "prompt = PromptTemplate.from_template(\n",
    "    template,\n",
    "    partial_variables={\"format_instructions\": output_parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | OpenAI() | output_parser\n",
    "\n",
    "output = chain.invoke({\"question\": \"6.25 한국전쟁은 언제 발발했나요?\"})\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1e828f-c099-4b88-bee9-2ec13e72bea8",
   "metadata": {},
   "source": [
    "### 7.3 JSON parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35606c2b-92da-4d9a-a08b-21e3ba8d4073",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(temperature=1)\n",
    "\n",
    "# Define your desired data structure.\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"question to set up a joke\")\n",
    "    punchline: str = Field(description=\"answer to resolve the joke\")\n",
    "\n",
    "# And a query intented to prompt a language model to populate the data structure.\n",
    "joke_query = \"재미난 이야기 해주세요. 한글로 해주세요\"\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = JsonOutputParser(pydantic_object=Joke)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | model | parser\n",
    "\n",
    "chain.invoke({\"query\": joke_query})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (llm)",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
