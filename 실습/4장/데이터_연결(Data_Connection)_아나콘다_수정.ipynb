{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90ffddca-002e-48a1-b046-cb18747faeda",
   "metadata": {},
   "source": [
    "# 데이터 연결\n",
    "## 1. 라이브러리 설치\n",
    "- 아나콘다에서 다음 라이브러리를 설치합니다. 다음 코드는 한줄씩 실행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13415685",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14419d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c693cd8d-e357-4221-aaf9-57a2e654b357",
   "metadata": {},
   "source": [
    "- **pypdf**: 파이썬에서 PDF 파일을 다루기 위한 라이브러리입니다. PDF 파일을 읽거나 수정할 때 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978b96e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pypdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8903f09-5d0c-4abe-877d-82ae9cb82ee2",
   "metadata": {},
   "source": [
    "- **tiktoken**: 오픈AI에서 제공하는 임베딩을 위한 라이브러리입니다. OpenAIEmbeddings을 사용하기 위해 필요합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c26110e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62541d9-b08c-427c-9bd4-ca4c2da94d33",
   "metadata": {},
   "source": [
    "- **faiss-cpu**: 페이스북(Facebook)의 AI 연구팀이 개발한 라이브러리로, 벡터의 유사도 검색을 위해 사용됩니다. \n",
    "- 만약 사용하는 컴퓨터가 GPU를 지원한다면 '!pip install faiss-gpu'로 설치해주세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2be409",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28484345-f39d-4158-a3e9-aee84d03627e",
   "metadata": {},
   "source": [
    "- **sentence-transformers**: 자연어 처리에서 문장 또는 단락을 벡터로 변환하기 위해 사용되는 라이브러리입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc926628",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351da784-2030-4273-a8da-c525f210f07d",
   "metadata": {},
   "source": [
    "- **langchain_community**: langchain_community는 langchain의 커뮤니티에서 개발한 모듈과 통합 기능들을 포함하는 라이브러리입니다. \n",
    "- 이 라이브러리를 통해 다양한 써드파티 서비스나 도구들과 쉽게 연동할 수 있습니다.\n",
    "- 책에서 제공하는 원본 소스에  추가된 내용입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c54c6f3-a3ac-472e-a3b4-671d797929ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain_community"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cd9ad3-d2ff-4583-b2d2-106850cdad5c",
   "metadata": {},
   "source": [
    "## 2. PDF 파일 불러와 보여주기\n",
    "- 코드에서 document[5].page_content[:5000]의 의미는 PDF 6페이지에서 5,000글자를 읽어오라는 의미입니다. \n",
    "- 일반적으로 페이지에 대한 인덱스는 0부터 시작하므로 document[0]이 1페이지며, document[5]은 6페이지가 됩니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1aa131f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"The_Adventures_of_Tom_Sawyer.pdf\")\n",
    "document = loader.load()\n",
    "document[5].page_content[:5000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c23f01-b931-479c-bf3a-dc91308dacbd",
   "metadata": {},
   "source": [
    "## 3. 임베딩 처리\n",
    "- 임베딩은 오픈 AI에서 제공하는 임베딩 모델을 사용하며, 벡터 데이터베이스로 파이스(FAISS)를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3075e30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-\" #openai 키 입력\n",
    "\n",
    "from langchain.vectorstores import FAISS\n",
    "#from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings() #임베딩 처리\n",
    "vectorstore = FAISS.from_documents(document, embeddings)\n",
    "print(vectorstore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9623c4c-7efd-4e88-bcd2-b6dae29d016a",
   "metadata": {},
   "source": [
    "- [테스트] 벡터 데이터베이스에 저장된 모든 청크들을 조회합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5150b7d-cd14-478a-99dd-2aaee261cdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 문서 조회\n",
    "all_documents = vectorstore.similarity_search(query=\"\", k=vectorstore.index.ntotal)\n",
    "\n",
    "print(f\"****** 크기: {vectorstore.index.ntotal} \")\n",
    "\n",
    "# 출력할 때 인덱스를 포함하여 표시\n",
    "for idx, doc in enumerate(all_documents):\n",
    "    print(f\"[{idx}][ {doc.page_content}]\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32616c18-4a57-43bc-93f7-39072d11997a",
   "metadata": {},
   "source": [
    "- [테스트] 특정 키워드로 조회한 결과 상위 2개를 보여줍니다.\n",
    "  + [langchain_core.vectorstores.VectorStore]( https://api.python.langchain.com/en/latest/vectorstores/langchain_core.vectorstores.VectorStore.html#langchain_core.vectorstores.VectorStore.similarity_search)\n",
    "  + [유사도 기반 검색 (Similarity search)](https://wikidocs.net/231578)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e15b457-f4c8-4a0d-99c6-6e102baf2fea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query = 'Where did Tom go?'\n",
    "docs = vectorstore.similarity_search(query,2)\n",
    "for doc in docs:\n",
    "    print(f\"[ {doc.page_content}]\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359b7974-1f86-47db-b008-8f864f170681",
   "metadata": {},
   "source": [
    "## 4. 검색기(RetrievalQA) 활용 (chain_type=\"stuff\")\n",
    "- 원하는 질문에 답변할 수 있도록 RetrievalQA를 활용합니다. \n",
    "- 원문 pdf 파일이 영문임에도 불구하고 한글이 얼마나 잘 인식되는지 확인하고자 합니다.\n",
    "- LLM 모델은 오픈AI에서 제공하는 gpt-4o-mini를 사용합니다.\n",
    "  + \"temperature=0\": 이 값은 모델이 가장 가능성이 높은 응답을 선택하도록 하여, 매우 보수적이고 일관된 답변을 생성. 창의성은 거의 없고, 질문에 대해 매우 정해진 방식으로 답변\n",
    "  + \"temperature=1\": 기본값으로, 적절한 수준의 창의성과 예측 가능성을 제공. 응답이 다채롭고 다양한 방식으로 나타날 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7731bc9d-ee8c-408c-907f-fb38967ad743",
   "metadata": {},
   "source": [
    "- [LangChain 긴 문서 다루기: Stuff, Refine, Map Reduce](https://pkgpl.org/2023/10/10/langchain-%EA%B8%B4-%EB%AC%B8%EC%84%9C-%EB%8B%A4%EB%A3%A8%EA%B8%B0/)\n",
    "- [LLMs를 활용한 문서 요약 가이드: Stuff, Map-Reduce, Refine 방법 총정리](https://teddylee777.github.io/langchain/summarize-chain/)\n",
    "  + Stuff: 단순히 모든 문서를 단일 프롬프트로 “넣는” 방식입니다. 이는 가장 간단한 접근 방식입니다.\n",
    "  + Map-reduce: 각 문서를 “map” 단계에서 개별적으로 요약한 다음, “reduce” 단계에서 요약본들을 최종 요약본으로 합치는 방식입니다\n",
    "  + Refine: 입력 문서를 순회하며 반복적으로 답변을 업데이트하여 응답을 구성합니다. 각 문서에 대해, 모든 비문서 입력, 현재 문서, 그리고 최신 중간 답변을 LLM chain에 전달하여 새로운 답변을 얻습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d217e243",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from langchain.chat_models import ChatOpenAI # The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0\n",
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(temperature=0,  # 창의성 0으로 설정 # 창의성 (0.0 ~ 1.0) # 일반적으로 0.7 ~ 1.0 사용\n",
    "                 model_name='gpt-4o-mini',  # 모델명 #gpt-4o-mini #gpt-3.5-turbo-16k\n",
    "                )\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "retrievalQA = RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=retriever)\n",
    "\n",
    "print(retrievalQA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f9a6cb-a555-4807-afec-b261b4d7d0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"마을 무덤에 있던 남자를 죽인 사람은 누구인가요?\"\n",
    "result = retrievalQA.invoke({\"query\": query})\n",
    "print(f\"[ {result['result']}]\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4581933d-7fc0-44cd-a66f-639cf69cac74",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"어디서 가져온 정보인가요?\"\n",
    "result = retrievalQA.invoke({\"query\": query})\n",
    "print(f\"[ {result['result']}]\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9069fbdd-ad02-4fb5-a820-fedd60fa64a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"마을 무덤에 있던 남자를 죽인 사람은 누구인가요? 어디서 가져온 정보인가요?\"\n",
    "result = retrievalQA.invoke({\"query\": query})\n",
    "print(f\"[ {result['result']}]\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06983f9-5050-41b8-b0a6-d207a60402e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"그리고, 뒤 이야기도 들려주세요. 어디서 가져온 정보인가요?\"\n",
    "result = retrievalQA.invoke({\"query\": query})\n",
    "print(f\"[ {result['result']}]\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54975a7-49fb-480f-bc67-59d6d13de204",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query = \"마을 무덤에 있던 남자를 죽인 사람은 누구인가요? 그리고, 뒤 이야기도 들려주세요. 어디서 가져온 정보인가요?\"\n",
    "result = retrievalQA.invoke({\"query\": query})\n",
    "print(f\"[ {result['result']}]\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9851d7ff-f944-4478-ac79-fbfa82f5abfd",
   "metadata": {},
   "source": [
    "## 5. 모델을 이용하여 문장을 벡터로 바꾸어보기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ef43a1-1800-48bc-9f56-7d4c0615114b",
   "metadata": {},
   "source": [
    "- OpenAIEmbeddings 모델을 이용하여 문장을 벡터로 바꾸어봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c2506d-fc43-4a9c-bb07-04cc5526ea0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "text = \"진희는 강아지를 키우고 있습니다. 진희가 키우고 있는 동물은?\"\n",
    "text_embedding = embeddings.embed_query(text)\n",
    "print(text_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01237479-46f1-465f-a03a-a60d847d3d18",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "- HuggingFaceEmbeddings 모델을 이용하여 문장을 벡터로 바꾸어봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77a4741-eef1-430b-aab3-aa707895f852",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name = \"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "text = \"진희는 강아지를 키우고 있습니다. 진희가 키우고 있는 동물은?\"\n",
    "text_embedding = embeddings.embed_query(text)\n",
    "print(text_embedding)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (llm)",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
