{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6a5a372-7389-42c1-bf28-1b04fb79c628",
   "metadata": {},
   "source": [
    "- LangChain 라이브러리를 설치하는 명령어입니다. LangChain은 LLM(대형 언어 모델)과 함께 작업할 때 유용한 도구들을 제공하는 파이썬 라이브러리입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91fcb318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (0.2.12)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (from langchain) (2.0.31)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (from langchain) (3.10.0)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.27 in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (from langchain) (0.2.28)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (from langchain) (0.2.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (from langchain) (0.1.96)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (from langchain) (1.24.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (from langchain) (2.8.2)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (from langchain) (8.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.3.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.27->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.27->langchain) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.27->langchain) (4.11.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.6)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (from requests<3,>=2->langchain) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (from requests<3,>=2->langchain) (2024.7.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.27->langchain) (3.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b89c484-c835-4abe-b142-12a776d9d1c0",
   "metadata": {},
   "source": [
    "- OpenAI의 Python 라이브러리를 설치하는 명령어입니다. 이 라이브러리는 OpenAI의 API와 상호작용하기 위해 필요합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6dbffa33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (1.38.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (from openai) (2.8.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\ktds\\anaconda3\\envs\\llm\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5c47a8-0e36-4ccc-bf25-5c5a1dd083fd",
   "metadata": {},
   "source": [
    "- os 모듈을 불러오고, OpenAI API 키를 환경 변수 OPENAI_API_KEY로 설정합니다. 이 키를 통해 OpenAI API에 접근할 수 있습니다.\n",
    "- langchain_openai 모듈에서 ChatOpenAI 클래스를 불러옵니다.\n",
    "- llm이라는 변수에 ChatOpenAI 객체를 할당합니다. 이 객체는 OpenAI의 GPT 모델을 사용하며, temperature=0은 출력의 창의성을 낮추기 위해 설정합니다. 모델 이름은 gpt-4o-mini로 설정되어 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfefdd4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.Completions object at 0x0000020714D0D160> async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x0000020714D15AC0> model_name='gpt-4o-mini' temperature=0.0 openai_api_key=SecretStr('**********') openai_proxy=''\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-proj-hXedXDpBrlTcFzTzuwsuT3BlbkFJNgLSTtQgf19RNc0i7K5b\" #openai 키 입력\n",
    "\n",
    "#from langchain.chat_models import ChatOpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(temperature=0,  # 창의성 0으로 설정 \n",
    "                 model_name='gpt-4o-mini',  # 모델명 #gpt-4o-mini #gpt-3.5-turbo-16k\n",
    "                )\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1156d415-2f23-4990-af73-60f0819eb94f",
   "metadata": {},
   "source": [
    "- 대화 기록을 관리하고 사용하는 데 필요한 클래스를 불러옵니다.\n",
    "- RunnableWithMessageHistory는 LLM을 사용한 대화 세션을 기록하고 관리하기 위해 사용되는 클래스입니다.\n",
    "- BaseChatMessageHistory와 InMemoryChatMessageHistory는 대화 내역을 저장하는 데 사용됩니다.\n",
    "- 대화 세션 기록을 저장하기 위한 store라는 딕셔너리를 초기화합니다. 이 딕셔너리는 세션 ID를 키로 하고, 그에 해당하는 대화 기록을 값으로 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "636e46dc-3724-40d6-b5fd-f7d2359de5b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "# https://python.langchain.com/v0.2/docs/tutorials/chatbot/\n",
    "#from langchain import ConversationChain\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "from langchain_core.chat_history import (\n",
    "    BaseChatMessageHistory,\n",
    "    InMemoryChatMessageHistory,\n",
    ")\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store = {}\n",
    "\n",
    "print(store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b8da2f-92ea-46cc-9f32-90267de9e168",
   "metadata": {},
   "source": [
    "- session_id를 받아 해당 세션의 대화 기록을 반환하는 함수입니다.\n",
    "- 만약 session_id에 해당하는 기록이 없으면 새로운 InMemoryChatMessageHistory 객체를 생성해 store에 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dffbbb96-4f99-4d44-a9ba-19cad4725e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc81492d-48b1-4cab-8401-96b9f22efe35",
   "metadata": {},
   "source": [
    "- 주석 처리된 ConversationChain 대신 RunnableWithMessageHistory를 사용하여 대화 체인을 구성합니다.\n",
    "- conversation 객체는 RunnableWithMessageHistory로 초기화되며, 여기서 llm을 사용하고 대화 기록을 관리하기 위해 get_session_history 함수를 전달합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "426786e2-7db8-470b-988b-f911951d7fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bound=RunnableBinding(bound=RunnableBinding(bound=RunnableLambda(_enter_history), config={'run_name': 'load_history'})\n",
      "| RunnableBranch(branches=[(RunnableBinding(bound=RunnableLambda(_is_not_async), config={'run_name': 'RunnableWithMessageHistoryInAsyncMode'}), RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x0000020714D0D160>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x0000020714D15AC0>, model_name='gpt-4o-mini', temperature=0.0, openai_api_key=SecretStr('**********'), openai_proxy=''), config_factories=[<function Runnable.with_alisteners.<locals>.<lambda> at 0x00000207125ABA60>]))], default=RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x0000020714D0D160>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x0000020714D15AC0>, model_name='gpt-4o-mini', temperature=0.0, openai_api_key=SecretStr('**********'), openai_proxy=''), config_factories=[<function Runnable.with_listeners.<locals>.<lambda> at 0x00000207125AB430>])), config={'run_name': 'RunnableWithMessageHistory'}) get_session_history=<function get_session_history at 0x00000207125ABAF0> history_factory_config=[ConfigurableFieldSpec(id='session_id', annotation=<class 'str'>, name='Session ID', description='Unique identifier for a session.', default='', is_shared=True, dependencies=None)]\n"
     ]
    }
   ],
   "source": [
    "#conversation = ConversationChain(llm=llm, verbose=True)\n",
    "# RunnableWithMessageHistory 구성\n",
    "conversation = RunnableWithMessageHistory(\n",
    "    runnable=llm,\n",
    "    get_session_history=get_session_history\n",
    ")\n",
    "print(conversation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366a5dac-ea2e-4f6d-a043-e93e303aee4f",
   "metadata": {},
   "source": [
    "- 주석 처리된 부분 이전에 사용되었던 predict 메서드를 대체하는 코드입니다.\n",
    "- session_id라는 변수에 고유한 세션 ID를 할당합니다. 이 ID를 통해 대화 세션을 식별하고, 해당 세션의 대화 기록을 유지할 수 있습니다.\n",
    "- invoke 메서드를 사용하여 대화 세션을 진행합니다.\n",
    "- 각 대화 세션의 출력 결과를 출력합니다. output1, output2, output3 각각의 내용을 확인하여 모델이 입력에 대해 어떻게 응답했는지 확인할 수 있습니다.\n",
    "- store 딕셔너리의 내용을 출력하여, 세션 기록이 잘 저장되었는지 확인합니다. store에는 세션 ID를 키로 하여, 해당 세션의 대화 기록이 저장됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4020a1bf-4b1d-4d21-ac42-e80334b4d951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- output1: [ 진희는 강아지를 키우고 있군요! 강아지와 함께하는 시간은 정말 소중하고 즐거운 경험이죠. 진희의 강아지는 어떤 품종인가요? 그리고 어떤 활동을 함께 하며 시간을 보내나요?]\n",
      "\n",
      "- output2: [ 영수는 고양이를 두 마리 키우고 있군요! 고양이는 독립적이면서도 애교가 많은 동물이라서 함께 지내는 재미가 쏠쏠하죠. 두 마리의 고양이는 어떤 품종인가요? 그리고 서로 잘 지내나요? 고양이와의 일상 이야기도 궁금합니다!]\n",
      "\n",
      "- output3: [ 진희는 강아지를 한 마리 키우고 있고, 영수는 고양이를 두 마리 키우고 있습니다. 따라서 진희와 영수가 키우는 동물의 총 수는 1 + 2 = 3마리입니다.]\n",
      "\n",
      "- store: [{'unique_session_id_1': InMemoryChatMessageHistory(messages=[HumanMessage(content='진희는 강아지를 한마리 키우고 있습니다.'), AIMessage(content='진희는 강아지를 키우고 있군요! 강아지와 함께하는 시간은 정말 소중하고 즐거운 경험이죠. 진희의 강아지는 어떤 품종인가요? 그리고 어떤 활동을 함께 하며 시간을 보내나요?', response_metadata={'token_usage': {'completion_tokens': 55, 'prompt_tokens': 21, 'total_tokens': 76}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_507c9469a1', 'finish_reason': 'stop', 'logprobs': None}, id='run-ea1d0a67-f5da-4388-937d-1307bc7ec39a-0', usage_metadata={'input_tokens': 21, 'output_tokens': 55, 'total_tokens': 76}), HumanMessage(content='영수는 고양이를 두마리 키우고 있습니다.'), AIMessage(content='영수는 고양이를 두 마리 키우고 있군요! 고양이는 독립적이면서도 애교가 많은 동물이라서 함께 지내는 재미가 쏠쏠하죠. 두 마리의 고양이는 어떤 품종인가요? 그리고 서로 잘 지내나요? 고양이와의 일상 이야기도 궁금합니다!', response_metadata={'token_usage': {'completion_tokens': 81, 'prompt_tokens': 98, 'total_tokens': 179}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_48196bc67a', 'finish_reason': 'stop', 'logprobs': None}, id='run-db37dabb-c549-4a99-84f8-46d591a38250-0', usage_metadata={'input_tokens': 98, 'output_tokens': 81, 'total_tokens': 179}), HumanMessage(content='진희와 영수가 키우는 동물은 총 몇마리?'), AIMessage(content='진희는 강아지를 한 마리 키우고 있고, 영수는 고양이를 두 마리 키우고 있습니다. 따라서 진희와 영수가 키우는 동물의 총 수는 1 + 2 = 3마리입니다.', response_metadata={'token_usage': {'completion_tokens': 55, 'prompt_tokens': 203, 'total_tokens': 258}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_48196bc67a', 'finish_reason': 'stop', 'logprobs': None}, id='run-1111bd24-4283-4d19-b7d8-5d7fc4a37952-0', usage_metadata={'input_tokens': 203, 'output_tokens': 55, 'total_tokens': 258})])}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# conversation.predict(input=\"진희는 강아지를 한마리 키우고 있습니다.\")\n",
    "# conversation.predict(input=\"영수는 고양이를 두마리 키우고 있습니다.\")\n",
    "# conversation.predict(input=\"진희와 영수가 키우는 동물은 총 몇마리?\")\n",
    "\n",
    "# 대화 세션 ID 설정\n",
    "session_id = \"unique_session_id_1\"\n",
    "\n",
    "# 대화 진행\n",
    "output1 = conversation.invoke(\n",
    "    {\"input\": \"진희는 강아지를 한마리 키우고 있습니다.\"},\n",
    "    config={\"configurable\": {\"session_id\": session_id}}\n",
    ")\n",
    "output2 = conversation.invoke(\n",
    "    {\"input\": \"영수는 고양이를 두마리 키우고 있습니다.\"},\n",
    "    config={\"configurable\": {\"session_id\": session_id}}\n",
    ")\n",
    "output3 = conversation.invoke(\n",
    "    {\"input\": \"진희와 영수가 키우는 동물은 총 몇마리?\"},\n",
    "    config={\"configurable\": {\"session_id\": session_id}}\n",
    ")\n",
    "\n",
    "# 출력 결과 보기\n",
    "print(f\"- output1: [ {output1.content}]\\n\")\n",
    "print(f\"- output2: [ {output2.content}]\\n\")\n",
    "print(f\"- output3: [ {output3.content}]\\n\")\n",
    "# 메모리 보기\n",
    "print(f\"- store: [{store}]\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (llm)",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
