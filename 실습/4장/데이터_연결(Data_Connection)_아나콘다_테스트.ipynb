{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90ffddca-002e-48a1-b046-cb18747faeda",
   "metadata": {},
   "source": [
    "# 데이터 연결\n",
    "## 1. 라이브러리 설치\n",
    "- 아나콘다에서 다음 라이브러리를 설치합니다. 다음 코드는 한줄씩 실행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13415685",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14419d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c693cd8d-e357-4221-aaf9-57a2e654b357",
   "metadata": {},
   "source": [
    "###### - **pypdf**: 파이썬에서 PDF 파일을 다루기 위한 라이브러리입니다. PDF 파일을 읽거나 수정할 때 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978b96e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pypdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8903f09-5d0c-4abe-877d-82ae9cb82ee2",
   "metadata": {},
   "source": [
    "###### - **tiktoken**: 오픈AI에서 제공하는 임베딩을 위한 라이브러리입니다. OpenAIEmbeddings을 사용하기 위해 필요합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c26110e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62541d9-b08c-427c-9bd4-ca4c2da94d33",
   "metadata": {},
   "source": [
    "###### - **faiss-cpu**: 페이스북(Facebook)의 AI 연구팀이 개발한 라이브러리로, 벡터의 유사도 검색을 위해 사용됩니다. \n",
    "###### - 만약 사용하는 컴퓨터가 GPU를 지원한다면 '!pip install faiss-gpu'로 설치해주세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2be409",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28484345-f39d-4158-a3e9-aee84d03627e",
   "metadata": {},
   "source": [
    "###### - **sentence-transformers**: 자연어 처리에서 문장 또는 단락을 벡터로 변환하기 위해 사용되는 라이브러리입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc926628",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351da784-2030-4273-a8da-c525f210f07d",
   "metadata": {},
   "source": [
    "###### - **langchain_community**: langchain_community는 langchain의 커뮤니티에서 개발한 모듈과 통합 기능들을 포함하는 라이브러리입니다. \n",
    "###### - 이 라이브러리를 통해 다양한 써드파티 서비스나 도구들과 쉽게 연동할 수 있습니다.\n",
    "###### - 책에서 제공하는 원본 소스에  추가된 내용입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c54c6f3-a3ac-472e-a3b4-671d797929ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain_community"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cd9ad3-d2ff-4583-b2d2-106850cdad5c",
   "metadata": {},
   "source": [
    "## 2. PDF 파일 불러와 보여주기\n",
    "- 코드에서 document[5].page_content[:5000]의 의미는 PDF 6페이지에서 5,000글자를 읽어오라는 의미입니다. \n",
    "- 일반적으로 페이지에 대한 인덱스는 0부터 시작하므로 document[0]이 1페이지며, document[5]은 6페이지가 됩니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1aa131f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"The_Adventures_of_Tom_Sawyer.pdf\")\n",
    "document = loader.load()\n",
    "document[5].page_content[:5000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c23f01-b931-479c-bf3a-dc91308dacbd",
   "metadata": {},
   "source": [
    "## 3. 임베딩 처리\n",
    "- 임베딩은 오픈 AI에서 제공하는 임베딩 모델을 사용하며, 벡터 데이터베이스로 파이스(FAISS)를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3075e30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-\" #openai 키 입력\n",
    "\n",
    "from langchain.vectorstores import FAISS\n",
    "#from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings() #임베딩 처리\n",
    "vectorstore = FAISS.from_documents(document, embeddings)\n",
    "print(vectorstore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9623c4c-7efd-4e88-bcd2-b6dae29d016a",
   "metadata": {},
   "source": [
    "- [테스트] 벡터 데이터베이스에 저장된 모든 청크들을 조회합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5150b7d-cd14-478a-99dd-2aaee261cdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 문서 조회\n",
    "all_documents = vectorstore.similarity_search(query=\"\", k=vectorstore.index.ntotal)\n",
    "\n",
    "print(f\"****** 크기: {vectorstore.index.ntotal} \")\n",
    "\n",
    "# 출력할 때 인덱스를 포함하여 표시\n",
    "for idx, doc in enumerate(all_documents):\n",
    "    print(f\"[{idx}][ {doc.page_content}]\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32616c18-4a57-43bc-93f7-39072d11997a",
   "metadata": {},
   "source": [
    "- [테스트] 특정 키워드로 조회한 결과 상위 2개를 보여줍니다.\n",
    "###### - [langchain_core.vectorstores.VectorStore]( https://api.python.langchain.com/en/latest/vectorstores/langchain_core.vectorstores.VectorStore.html#langchain_core.vectorstores.VectorStore.similarity_search)\n",
    "###### - [유사도 기반 검색 (Similarity search)](https://wikidocs.net/231578)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e15b457-f4c8-4a0d-99c6-6e102baf2fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'Where did Tom go?'\n",
    "docs = vectorstore.similarity_search(query,2)\n",
    "for doc in docs:\n",
    "    print(f\"[ {doc.page_content}]\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a036aae-229e-4434-8109-4bdad7c7dc82",
   "metadata": {},
   "source": [
    "## 4. 검색기(RetrievalQA) 활용 (rag-prompt)\n",
    "###### - 원하는 질문에 답변할 수 있도록 RetrievalQA를 활용합니다. \n",
    "###### - 원문 pdf 파일이 영문임에도 불구하고 한글이 얼마나 잘 인식되는지 확인하고자 합니다.\n",
    "###### - LLM 모델은 오픈AI에서 제공하는 gpt-4o-mini를 사용합니다.\n",
    "> ###### \"temperature=0\": 이 값은 모델이 가장 가능성이 높은 응답을 선택하도록 하여, 매우 보수적이고 일관된 답변을 생성. 창의성은 거의 없고, 질문에 대해 매우 정해진 방식으로 답변\n",
    "> ###### \"temperature=1\": 기본값으로, 적절한 수준의 창의성과 예측 가능성을 제공. 응답이 다채롭고 다양한 방식으로 나타날 수 있음\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb80fec-cb27-44f4-8ee5-6263bca52fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/langchain-ai/langsmith-cookbook/blob/main/hub-examples/retrieval-qa-chain/retrieval-qa.ipynb\n",
    "!pip install langchainhub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b0ea61-4dbb-4e2a-8911-1a93b86dd31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG prompt\n",
    "from langchain import hub\n",
    "\n",
    "# Loads the latest version\n",
    "prompt = hub.pull(\"rlm/rag-prompt\", api_url=\"https://api.hub.langchain.com\")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd96c993-0cb8-4d28-8dec-1f0f5372f864",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from langchain.chat_models import ChatOpenAI # The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0\n",
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(temperature=0,  # 창의성 0으로 설정 # 창의성 (0.0 ~ 1.0) # 일반적으로 0.7 ~ 1.0 사용\n",
    "                 model_name='gpt-4o-mini',  # 모델명 #gpt-4o-mini #gpt-3.5-turbo-16k\n",
    "                )\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm, \n",
    "    retriever=retriever, \n",
    "    chain_type_kwargs={\"prompt\": prompt}\n",
    ")\n",
    "print(qa_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4395d477-73f1-4eda-b97d-ad6f9735418d",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Joe와 Tom은 누구인가요? 어디서 가져온 정보인가요? \"\n",
    "result = qa_chain.invoke({\"query\": question})\n",
    "print(f\"[ {result['result']}]\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6624e4d9-2497-427b-9c98-dbb6d2730c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"그리고, 마을 무덤에 있던 남자를 죽인 사람은 누구인가요? 뒤 이야기도 들려주세요. 한글로 말해주세요. 어디서 가져온 정보인가요?\"\n",
    "result = qa_chain.invoke({\"query\": question})\n",
    "print(f\"[ {result['result']}]\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505d44a6-9646-495b-88d0-8a6f6c4f20b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"바이든이 누구인가요? 한글로 상세히 말해주세요. 고향과 나이와 가족관계는 어떻게 되나요? 어디서 가져온 정보인가요? LLM에서 가져온건가요?\"\n",
    "result = qa_chain.invoke({\"query\": question})\n",
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddd23c2-3c62-42e9-ad58-5e77813e9bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"바이든이 누구인가요? 한글로 상세히 말해주세요. 바이든이 기르는 개의 이름은 무엇인가요? 어디서 가져온 정보인가요? LLM에서 가져온건가요?\"\n",
    "result = qa_chain.invoke({\"query\": question})\n",
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a5b37e-a58c-48d3-9e48-69461d0b9e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"바이든이 누구인가요? 한글로 상세히 말해주세요. 고향과 나이와 가족관계는 어떻게 되나요? 바이든이 기르는 개의 이름은 무엇인가요? 어디서 가져온 정보인가요? LLM에서 가져온건가요?\"\n",
    "result = qa_chain.invoke({\"query\": question})\n",
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca94466-da54-455b-abf4-fc5ac06b25a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"미국 대통령 바이든에 대해 설명해주세요. 어디서 가져온 정보인가요?\"\n",
    "result = qa_chain.invoke({\"query\": question})\n",
    "print(f\"[ {result['result']}]\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3a98b4-cdc4-4b75-b2d1-46aece062718",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"톰소여의모험이라는 소설에서 톰의 나이는 몇살인가요? 한글로 말해주세요. 어디서 가져온 정보인가요?\"\n",
    "result = qa_chain.invoke({\"query\": question})\n",
    "print(f\"[ {result['result']}]\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0852a131-e72b-4915-bab5-09ae7ac688a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Hannibal, Missouri는 Young Samuel이 살았던 곳이지 Tom이 살던 곳은 아닙니다.Tom이 살고 있는 곳은 어디인가요? 한글로 말해주세요. 어디서 가져온 정보인가요?\"\n",
    "result = qa_chain.invoke({\"query\": question})\n",
    "print(f\"[ {result['result']}]\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359b7974-1f86-47db-b008-8f864f170681",
   "metadata": {},
   "source": [
    "## 5. 검색기(RetrievalQA) 활용 (chain_type=\"stuff\")\n",
    "###### - 원하는 질문에 답변할 수 있도록 RetrievalQA를 활용합니다. \n",
    "###### - 원문 pdf 파일이 영문임에도 불구하고 한글이 얼마나 잘 인식되는지 확인하고자 합니다.\n",
    "###### - LLM 모델은 오픈AI에서 제공하는 gpt-4o-mini를 사용합니다.\n",
    "> ###### \"temperature=0\": 이 값은 모델이 가장 가능성이 높은 응답을 선택하도록 하여, 매우 보수적이고 일관된 답변을 생성. 창의성은 거의 없고, 질문에 대해 매우 정해진 방식으로 답변\n",
    "> ###### \"temperature=1\": 기본값으로, 적절한 수준의 창의성과 예측 가능성을 제공. 응답이 다채롭고 다양한 방식으로 나타날 수 있음\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d217e243",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from langchain.chat_models import ChatOpenAI # The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0\n",
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(temperature=0,  # 창의성 0으로 설정 # 창의성 (0.0 ~ 1.0) # 일반적으로 0.7 ~ 1.0 사용\n",
    "                 model_name='gpt-4o-mini',  # 모델명 #gpt-4o-mini #gpt-3.5-turbo-16k\n",
    "                )\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "retrievalQA = RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=retriever)\n",
    "\n",
    "print(retrievalQA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f9a6cb-a555-4807-afec-b261b4d7d0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Joe와 Tom은 누구인가요? 어디서 가져온 정보인가요? \"\n",
    "result = retrievalQA.invoke({\"query\": query})\n",
    "print(f\"[ {result['result']}]\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54975a7-49fb-480f-bc67-59d6d13de204",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query = \"그리고, 마을 무덤에 있던 남자를 죽인 사람은 누구인가요? 뒤 이야기도 들려주세요. 어디서 가져온 정보인가요?\"\n",
    "result = retrievalQA.invoke({\"query\": query})\n",
    "print(f\"[ {result['result']}]\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa98a42-f7ab-457d-bbca-d07243518dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"톰소여의모험이라는 소설에서 톰의 나이는 몇살인가요? 어디서 가져온 정보인가요??\"\n",
    "result = retrievalQA.invoke({\"query\": query})\n",
    "print(f\"[ {result['result']}]\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9be4d4-cfa4-4d83-a495-13cab36fee16",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Hannibal, Missouri는 Young Samuel이 살았던 곳이지 Tom이 살던 곳은 아닙니다.Tom이 살고 있는 곳은 어디인가요? 어디서 가져온 정보인가요?\"\n",
    "result = retrievalQA.invoke({\"query\": query})\n",
    "print(f\"[ {result['result']}]\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85bc73f-be90-4ea3-9acb-e95af9f990ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"바이든이 누구인가요? 한글로 상세히 말해주세요\"\n",
    "result = retrievalQA.invoke({\"query\": query})\n",
    "print(f\"[ {result['result']}]\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e65aafb-3252-45c5-ae5e-699dc0d0eece",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"미국 대통령 바이든에 대해 설명해주세요\"\n",
    "result = retrievalQA.invoke({\"query\": query})\n",
    "print(f\"[ {result['result']}]\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (llm)",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
